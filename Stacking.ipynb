{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = \"/mnt/d/Data/mangaki-data-challenge/latest/\"\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featurepath = data+\"../features/level1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for random forest\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'rf',\n",
    "    'objective': 'binary',\n",
    "    'num_leaves': 550,\n",
    "    'min_data_in_leaf': 6,\n",
    "    'feature_fraction': 0.55,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'lambda_l1': 0,\n",
    "    'min_gain_to_split': 0,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "def training(train, valid):\n",
    "    X = lgb.Dataset(train.drop(['user_id', 'work_id', 'rating'], axis=1), train['rating'])\n",
    "    gbdt = lgb.train(params, X, num_boost_round=116)\n",
    "    Yvp = gbdt.predict(valid.drop(['user_id', 'work_id', 'rating'], axis=1))\n",
    "    return Yvp\n",
    "\n",
    "def cv():\n",
    "    rst = []\n",
    "    for fold in [1,2,3]:\n",
    "        t = pd.read_csv(data+'train_{0}.csv'.format(str(fold)))\n",
    "        v = pd.read_csv(data+'valid_{0}.csv'.format(str(fold)))\n",
    "        t['item_category'] = t.item_category.astype('category')\n",
    "        v['item_category'] = v.item_category.astype('category')\n",
    "        pv = training(t, v)\n",
    "        f = v[['user_id', 'work_id', 'rating']].copy()\n",
    "        f['rf_prob'] = pv\n",
    "        rst.append(f)\n",
    "    pd.concat(rst).to_csv(featurepath+'rf_train.csv', index=False)\n",
    "    \n",
    "def testprob():\n",
    "    t = pd.read_csv(data+'train_0.csv')\n",
    "    v = pd.read_csv(data+'test_0.csv')\n",
    "    t['item_category'] = t.item_category.astype('category')\n",
    "    v['item_category'] = v.item_category.astype('category')\n",
    "    X = lgb.Dataset(t.drop(['user_id', 'work_id', 'rating'], axis=1), t['rating'])\n",
    "    gbdt = lgb.train(params, X, num_boost_round=116)\n",
    "    Yvp = gbdt.predict(v.drop(['user_id', 'work_id'], axis=1))\n",
    "    f = v[['user_id', 'work_id']].copy()\n",
    "    f['rf_prob'] = Yvp\n",
    "    f.to_csv(featurepath+'rf_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for gbdt\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'num_leaves': 40,\n",
    "    'min_data_in_leaf': 90,\n",
    "    'feature_fraction': 0.6,\n",
    "    'bagging_fraction': 0.96,\n",
    "    'bagging_freq': 1,\n",
    "    'lambda_l1': 0,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "def training(train, valid):\n",
    "    X = lgb.Dataset(train.drop(['user_id', 'work_id', 'rating'], axis=1), train['rating'])\n",
    "    gbdt = lgb.train(params, X, num_boost_round=119)\n",
    "    Yvp = gbdt.predict(valid.drop(['user_id', 'work_id', 'rating'], axis=1))\n",
    "    return Yvp\n",
    "\n",
    "def cv():\n",
    "    rst = []\n",
    "    for fold in [1,2,3]:\n",
    "        t = pd.read_csv(data+'train_{0}.csv'.format(str(fold)))\n",
    "        v = pd.read_csv(data+'valid_{0}.csv'.format(str(fold)))\n",
    "        t['item_category'] = t.item_category.astype('category')\n",
    "        v['item_category'] = v.item_category.astype('category')\n",
    "        pv = training(t, v)\n",
    "        f = v[['user_id', 'work_id', 'rating']].copy()\n",
    "        f['gbdt_prob'] = pv\n",
    "        rst.append(f)\n",
    "    pd.concat(rst).to_csv(featurepath+'gbdt_train.csv', index=False)\n",
    "    \n",
    "def testprob():\n",
    "    t = pd.read_csv(data+'train_0.csv')\n",
    "    v = pd.read_csv(data+'test_0.csv')\n",
    "    t['item_category'] = t.item_category.astype('category')\n",
    "    v['item_category'] = v.item_category.astype('category')\n",
    "    X = lgb.Dataset(t.drop(['user_id', 'work_id', 'rating'], axis=1), t['rating'])\n",
    "    gbdt = lgb.train(params, X, num_boost_round=116)\n",
    "    Yvp = gbdt.predict(v.drop(['user_id', 'work_id'], axis=1))\n",
    "    f = v[['user_id', 'work_id']].copy()\n",
    "    f['gbdt_prob'] = Yvp\n",
    "    f.to_csv(featurepath+'gbdt_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for fm\n",
    "from scipy.sparse import hstack\n",
    "from fastFM import sgd\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "libfmpath = \"/mnt/d/Data/mangaki-data-challenge/libfm/\"\n",
    "\n",
    "params = {\n",
    "    'n_iter':340000, \n",
    "    'init_stdev':0.01,\n",
    "    'l2_reg_w':0.00025,\n",
    "    'l2_reg_V':0.5,\n",
    "    'rank':1,\n",
    "    'step_size':0.02\n",
    "}\n",
    "\n",
    "def train_fm(train, valid, trainy):\n",
    "    fm = sgd.FMClassification(**params)\n",
    "    fm.fit(train, np.require(trainy*2-1, dtype=np.int))\n",
    "    return fm.predict_proba(valid)\n",
    "\n",
    "def cv():\n",
    "    rst = []\n",
    "    for fold in [1,2,3]:\n",
    "        train, ty = load_svmlight_file(libfmpath+\"train_{0}.csv\".format(fold))\n",
    "        valid, _ = load_svmlight_file(libfmpath+\"valid_{0}.csv\".format(fold))\n",
    "        pv = train_fm(train, valid, ty)\n",
    "        v = pd.read_csv(data+'valid_{0}.csv'.format(str(fold)))\n",
    "        f = v[['user_id', 'work_id', 'rating']].copy()\n",
    "        f['fm_prob'] = pv\n",
    "        rst.append(f)\n",
    "    pd.concat(rst).to_csv(featurepath+'fm_train.csv', index=False)\n",
    "    \n",
    "def testprob():\n",
    "    v = pd.read_csv(data+'test_0.csv')\n",
    "    train, ty = load_svmlight_file(libfmpath+\"train_0.csv\", zero_based=True)\n",
    "    test, _ = load_svmlight_file(libfmpath+\"test_0.csv\")\n",
    "    fm = sgd.FMClassification(**params)\n",
    "    fm.fit(train, np.require(ty*2-1, dtype=np.int))\n",
    "    Y = fm.predict_proba(test)\n",
    "    f = v[['user_id', 'work_id']].copy()\n",
    "    f['fm_prob'] = Y\n",
    "    f.to_csv(featurepath+'fm_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv()\n",
    "testprob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1 = pd.read_csv(data+\"../features/level1/gbdt_train.csv\", usecols = ['user_id','work_id','gbdt_prob'])\n",
    "s2 = pd.read_csv(data+\"../features/level1/rf_train.csv\", usecols = ['user_id','work_id','rf_prob'])\n",
    "s3 = pd.read_csv(data+\"../features/level1/fm_train.csv\", usecols = ['user_id','work_id','fm_prob'])\n",
    "\n",
    "for i in [1, 2, 3]:\n",
    "    train = pd.read_csv(data+\"../baseline/train_{0}.csv\".format(i), usecols = ['user_id','work_id','rating'])\n",
    "    if i != 0:\n",
    "        valid = pd.read_csv(data+\"../baseline/valid_{0}.csv\".format(i), usecols = ['user_id','work_id','rating'])\n",
    "    else:\n",
    "        valid = pd.read_csv(data+\"../baseline/test_{0}.csv\".format(i), usecols = ['user_id','work_id'])\n",
    "\n",
    "    train = train.merge(s1, on=['user_id', 'work_id'], how='left').\\\n",
    "                  merge(s2, on=['user_id', 'work_id'], how='left').\\\n",
    "                  merge(s3, on=['user_id', 'work_id'], how='left')\n",
    "    valid = valid.merge(s1, on=['user_id', 'work_id'], how='left').\\\n",
    "                  merge(s2, on=['user_id', 'work_id'], how='left').\\\n",
    "                  merge(s3, on=['user_id', 'work_id'], how='left')\n",
    "\n",
    "    train.to_csv(data+\"../baseline/level1/train_{0}.csv\".format(i), index=False)\n",
    "    valid.to_csv(data+\"../baseline/level1/valid_{0}.csv\".format(i), index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(data+\"../baseline/train_0.csv\", usecols = ['user_id','work_id','rating'])\n",
    "train = train.merge(s1, on=['user_id', 'work_id'], how='left').\\\n",
    "              merge(s2, on=['user_id', 'work_id'], how='left').\\\n",
    "              merge(s3, on=['user_id', 'work_id'], how='left')\n",
    "train.to_csv(data+\"../baseline/level1/train_0.csv\", index=False)\n",
    "\n",
    "s1 = pd.read_csv(data+\"../features/level1/gbdt_test.csv\", usecols = ['user_id','work_id','gbdt_prob'])\n",
    "s2 = pd.read_csv(data+\"../features/level1/rf_test.csv\", usecols = ['user_id','work_id','rf_prob'])\n",
    "s3 = pd.read_csv(data+\"../features/level1/fm_test.csv\", usecols = ['user_id','work_id','fm_prob'])\n",
    "valid = pd.read_csv(data+\"../baseline/test_0.csv\", usecols = ['user_id','work_id'])\n",
    "valid = valid.merge(s1, on=['user_id', 'work_id'], how='left').\\\n",
    "              merge(s2, on=['user_id', 'work_id'], how='left').\\\n",
    "              merge(s3, on=['user_id', 'work_id'], how='left')\n",
    "valid.to_csv(data+\"../baseline/level1/valid_0.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
