{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import gc\n",
    "\n",
    "gc.enable()\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'auc'},\n",
    "    'num_leaves': 40,\n",
    "    'min_data_in_leaf': 90,\n",
    "    'feature_fraction': 0.6,\n",
    "    'bagging_fraction': 0.96,\n",
    "    'bagging_freq': 1,\n",
    "    'lambda_l1': 0,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "#params = {\n",
    "#    'task': 'train',\n",
    "#    'boosting_type': 'rf',\n",
    "#    'objective': 'binary',\n",
    "#    'metric': {'auc'},\n",
    "#    'num_leaves': 550,\n",
    "#    'min_data_in_leaf': 6,\n",
    "#    'feature_fraction': 0.55,\n",
    "#    'bagging_fraction': 0.8,\n",
    "#    'bagging_freq': 1,\n",
    "#    'lambda_l1': 0,\n",
    "#    'min_gain_to_split': 0,\n",
    "#    'verbose': 0\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = \"/mnt/d/Data/mangaki-data-challenge/baseline/level1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# level1 param\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'auc'},\n",
    "    'num_leaves': 2,\n",
    "    'min_data_in_leaf': 400,\n",
    "    'feature_fraction': 1,\n",
    "    'bagging_fraction': 0.91,\n",
    "    'bagging_freq': 1,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training(train, valid):\n",
    "    X = lgb.Dataset(train.drop(['user_id', 'work_id', 'rating'], axis=1), train['rating'])\n",
    "    V = lgb.Dataset(valid.drop(['user_id', 'work_id', 'rating'], axis=1), valid['rating'], reference=X)\n",
    "    gbdt = lgb.train(params, X, valid_sets=[X,V], num_boost_round=200, early_stopping_rounds=20, verbose_eval=True)\n",
    "    Yvp = gbdt.predict(valid.drop(['user_id', 'work_id', 'rating'], axis=1), num_iteration=gbdt.best_iteration)\n",
    "    Ytp = gbdt.predict(train.drop(['user_id', 'work_id', 'rating'], axis=1), num_iteration=gbdt.best_iteration)\n",
    "    return (roc_auc_score(train['rating'].values, Ytp), roc_auc_score(valid['rating'].values, Yvp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv(param, paramlst):\n",
    "    trainauc = [0.0]*len(paramlst)\n",
    "    validauc = [0.0]*len(paramlst)\n",
    "    for i, p in enumerate(paramlst):\n",
    "        params[param]=p\n",
    "        tv = [0,0,0]\n",
    "        vv = [0,0,0]\n",
    "        for fold in [1,2,3]:\n",
    "            t = pd.read_csv(data+'train_{0}.csv'.format(str(fold)))\n",
    "            v = pd.read_csv(data+'valid_{0}.csv'.format(str(fold)))\n",
    "            #t['item_category'] = t.item_category.astype('category')\n",
    "            #v['item_category'] = v.item_category.astype('category')\n",
    "            tv[fold-1], vv[fold-1] = training(t, v)\n",
    "        trainauc[i]=np.mean(tv)\n",
    "        validauc[i]=np.mean(vv)\n",
    "    paramtable = pd.DataFrame({\n",
    "        'TrainingSet': trainauc,\n",
    "        'ValidationSet': validauc\n",
    "    }, columns=['TrainingSet', 'ValidationSet'], index=pd.Index(paramlst, name=param))\n",
    "    print(paramtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.755659\tvalid_1's auc: 0.760444\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[2]\ttraining's auc: 0.77528\tvalid_1's auc: 0.780192\n",
      "[3]\ttraining's auc: 0.801813\tvalid_1's auc: 0.80251\n",
      "[4]\ttraining's auc: 0.811368\tvalid_1's auc: 0.808805\n",
      "[5]\ttraining's auc: 0.816753\tvalid_1's auc: 0.815829\n",
      "[6]\ttraining's auc: 0.817218\tvalid_1's auc: 0.816259\n",
      "[7]\ttraining's auc: 0.817199\tvalid_1's auc: 0.816203\n",
      "[8]\ttraining's auc: 0.817401\tvalid_1's auc: 0.816342\n",
      "[9]\ttraining's auc: 0.824505\tvalid_1's auc: 0.821173\n",
      "[10]\ttraining's auc: 0.827289\tvalid_1's auc: 0.82535\n",
      "[11]\ttraining's auc: 0.833293\tvalid_1's auc: 0.83003\n",
      "[12]\ttraining's auc: 0.833537\tvalid_1's auc: 0.830444\n",
      "[13]\ttraining's auc: 0.833961\tvalid_1's auc: 0.830414\n",
      "[14]\ttraining's auc: 0.834486\tvalid_1's auc: 0.830533\n",
      "[15]\ttraining's auc: 0.836468\tvalid_1's auc: 0.831551\n",
      "[16]\ttraining's auc: 0.836487\tvalid_1's auc: 0.831425\n",
      "[17]\ttraining's auc: 0.836536\tvalid_1's auc: 0.83142\n",
      "[18]\ttraining's auc: 0.836544\tvalid_1's auc: 0.831447\n",
      "[19]\ttraining's auc: 0.836547\tvalid_1's auc: 0.831671\n",
      "[20]\ttraining's auc: 0.839088\tvalid_1's auc: 0.833823\n",
      "[21]\ttraining's auc: 0.839082\tvalid_1's auc: 0.833788\n",
      "[22]\ttraining's auc: 0.84003\tvalid_1's auc: 0.834829\n",
      "[23]\ttraining's auc: 0.840242\tvalid_1's auc: 0.835021\n",
      "[24]\ttraining's auc: 0.841398\tvalid_1's auc: 0.836212\n",
      "[25]\ttraining's auc: 0.841544\tvalid_1's auc: 0.836736\n",
      "[26]\ttraining's auc: 0.841547\tvalid_1's auc: 0.836741\n",
      "[27]\ttraining's auc: 0.842679\tvalid_1's auc: 0.837672\n",
      "[28]\ttraining's auc: 0.842754\tvalid_1's auc: 0.837827\n",
      "[29]\ttraining's auc: 0.842822\tvalid_1's auc: 0.838054\n",
      "[30]\ttraining's auc: 0.843039\tvalid_1's auc: 0.838745\n",
      "[31]\ttraining's auc: 0.843029\tvalid_1's auc: 0.839056\n",
      "[32]\ttraining's auc: 0.842968\tvalid_1's auc: 0.839112\n",
      "[33]\ttraining's auc: 0.843131\tvalid_1's auc: 0.839051\n",
      "[34]\ttraining's auc: 0.843135\tvalid_1's auc: 0.839253\n",
      "[35]\ttraining's auc: 0.843544\tvalid_1's auc: 0.839489\n",
      "[36]\ttraining's auc: 0.843567\tvalid_1's auc: 0.839562\n",
      "[37]\ttraining's auc: 0.843585\tvalid_1's auc: 0.839517\n",
      "[38]\ttraining's auc: 0.843734\tvalid_1's auc: 0.839804\n",
      "[39]\ttraining's auc: 0.843917\tvalid_1's auc: 0.840052\n",
      "[40]\ttraining's auc: 0.843928\tvalid_1's auc: 0.840072\n",
      "[41]\ttraining's auc: 0.84393\tvalid_1's auc: 0.840148\n",
      "[42]\ttraining's auc: 0.843998\tvalid_1's auc: 0.840354\n",
      "[43]\ttraining's auc: 0.844211\tvalid_1's auc: 0.840642\n",
      "[44]\ttraining's auc: 0.84423\tvalid_1's auc: 0.84067\n",
      "[45]\ttraining's auc: 0.84425\tvalid_1's auc: 0.840708\n",
      "[46]\ttraining's auc: 0.844354\tvalid_1's auc: 0.840736\n",
      "[47]\ttraining's auc: 0.844356\tvalid_1's auc: 0.840758\n",
      "[48]\ttraining's auc: 0.844361\tvalid_1's auc: 0.840732\n",
      "[49]\ttraining's auc: 0.844395\tvalid_1's auc: 0.840746\n",
      "[50]\ttraining's auc: 0.84439\tvalid_1's auc: 0.840762\n",
      "[51]\ttraining's auc: 0.844379\tvalid_1's auc: 0.840855\n",
      "[52]\ttraining's auc: 0.844424\tvalid_1's auc: 0.840888\n",
      "[53]\ttraining's auc: 0.844463\tvalid_1's auc: 0.840893\n",
      "[54]\ttraining's auc: 0.844459\tvalid_1's auc: 0.840961\n",
      "[55]\ttraining's auc: 0.844524\tvalid_1's auc: 0.840927\n",
      "[56]\ttraining's auc: 0.844529\tvalid_1's auc: 0.840957\n",
      "[57]\ttraining's auc: 0.844533\tvalid_1's auc: 0.840988\n",
      "[58]\ttraining's auc: 0.84451\tvalid_1's auc: 0.841016\n",
      "[59]\ttraining's auc: 0.844521\tvalid_1's auc: 0.840999\n",
      "[60]\ttraining's auc: 0.844525\tvalid_1's auc: 0.841014\n",
      "[61]\ttraining's auc: 0.844546\tvalid_1's auc: 0.840966\n",
      "[62]\ttraining's auc: 0.844554\tvalid_1's auc: 0.840931\n",
      "[63]\ttraining's auc: 0.844549\tvalid_1's auc: 0.840969\n",
      "[64]\ttraining's auc: 0.844546\tvalid_1's auc: 0.841028\n",
      "[65]\ttraining's auc: 0.844579\tvalid_1's auc: 0.840994\n",
      "[66]\ttraining's auc: 0.84457\tvalid_1's auc: 0.841018\n",
      "[67]\ttraining's auc: 0.844609\tvalid_1's auc: 0.841014\n",
      "[68]\ttraining's auc: 0.844611\tvalid_1's auc: 0.841023\n",
      "[69]\ttraining's auc: 0.844634\tvalid_1's auc: 0.841061\n",
      "[70]\ttraining's auc: 0.844646\tvalid_1's auc: 0.841053\n",
      "[71]\ttraining's auc: 0.84465\tvalid_1's auc: 0.841062\n",
      "[72]\ttraining's auc: 0.844654\tvalid_1's auc: 0.841088\n",
      "[73]\ttraining's auc: 0.844671\tvalid_1's auc: 0.841083\n",
      "[74]\ttraining's auc: 0.844679\tvalid_1's auc: 0.841075\n",
      "[75]\ttraining's auc: 0.844684\tvalid_1's auc: 0.841094\n",
      "[76]\ttraining's auc: 0.844679\tvalid_1's auc: 0.84106\n",
      "[77]\ttraining's auc: 0.844671\tvalid_1's auc: 0.841046\n",
      "[78]\ttraining's auc: 0.844658\tvalid_1's auc: 0.84106\n",
      "[79]\ttraining's auc: 0.844656\tvalid_1's auc: 0.841107\n",
      "[80]\ttraining's auc: 0.84465\tvalid_1's auc: 0.841104\n",
      "[81]\ttraining's auc: 0.84465\tvalid_1's auc: 0.841106\n",
      "[82]\ttraining's auc: 0.84465\tvalid_1's auc: 0.841118\n",
      "[83]\ttraining's auc: 0.84466\tvalid_1's auc: 0.841123\n",
      "[84]\ttraining's auc: 0.844654\tvalid_1's auc: 0.841122\n",
      "[85]\ttraining's auc: 0.84466\tvalid_1's auc: 0.841128\n",
      "[86]\ttraining's auc: 0.844662\tvalid_1's auc: 0.841113\n",
      "[87]\ttraining's auc: 0.84465\tvalid_1's auc: 0.841103\n",
      "[88]\ttraining's auc: 0.844652\tvalid_1's auc: 0.841104\n",
      "[89]\ttraining's auc: 0.844662\tvalid_1's auc: 0.841207\n",
      "[90]\ttraining's auc: 0.844672\tvalid_1's auc: 0.84119\n",
      "[91]\ttraining's auc: 0.844687\tvalid_1's auc: 0.841175\n",
      "[92]\ttraining's auc: 0.84469\tvalid_1's auc: 0.841186\n",
      "[93]\ttraining's auc: 0.844672\tvalid_1's auc: 0.841201\n",
      "[94]\ttraining's auc: 0.844656\tvalid_1's auc: 0.841221\n",
      "[95]\ttraining's auc: 0.844657\tvalid_1's auc: 0.841217\n",
      "[96]\ttraining's auc: 0.84474\tvalid_1's auc: 0.841089\n",
      "[97]\ttraining's auc: 0.844738\tvalid_1's auc: 0.841213\n",
      "[98]\ttraining's auc: 0.844743\tvalid_1's auc: 0.841216\n",
      "[99]\ttraining's auc: 0.844741\tvalid_1's auc: 0.841207\n",
      "[100]\ttraining's auc: 0.844764\tvalid_1's auc: 0.841154\n",
      "[101]\ttraining's auc: 0.84469\tvalid_1's auc: 0.84102\n",
      "[102]\ttraining's auc: 0.844732\tvalid_1's auc: 0.840967\n",
      "[103]\ttraining's auc: 0.844734\tvalid_1's auc: 0.840968\n",
      "[104]\ttraining's auc: 0.844754\tvalid_1's auc: 0.840944\n",
      "[105]\ttraining's auc: 0.844758\tvalid_1's auc: 0.84095\n",
      "[106]\ttraining's auc: 0.844862\tvalid_1's auc: 0.840806\n",
      "[107]\ttraining's auc: 0.844866\tvalid_1's auc: 0.840811\n",
      "[108]\ttraining's auc: 0.844858\tvalid_1's auc: 0.840806\n",
      "[109]\ttraining's auc: 0.844845\tvalid_1's auc: 0.840827\n",
      "[110]\ttraining's auc: 0.844862\tvalid_1's auc: 0.840826\n",
      "[111]\ttraining's auc: 0.844871\tvalid_1's auc: 0.840841\n",
      "[112]\ttraining's auc: 0.844881\tvalid_1's auc: 0.840839\n",
      "[113]\ttraining's auc: 0.844908\tvalid_1's auc: 0.840834\n",
      "[114]\ttraining's auc: 0.844896\tvalid_1's auc: 0.840851\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's auc: 0.844656\tvalid_1's auc: 0.841221\n",
      "[1]\ttraining's auc: 0.761135\tvalid_1's auc: 0.748925\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[2]\ttraining's auc: 0.779184\tvalid_1's auc: 0.76877\n",
      "[3]\ttraining's auc: 0.794591\tvalid_1's auc: 0.789145\n",
      "[4]\ttraining's auc: 0.809539\tvalid_1's auc: 0.805403\n",
      "[5]\ttraining's auc: 0.809902\tvalid_1's auc: 0.806096\n",
      "[6]\ttraining's auc: 0.81386\tvalid_1's auc: 0.809161\n",
      "[7]\ttraining's auc: 0.813923\tvalid_1's auc: 0.808689\n",
      "[8]\ttraining's auc: 0.819992\tvalid_1's auc: 0.814671\n",
      "[9]\ttraining's auc: 0.822939\tvalid_1's auc: 0.819321\n",
      "[10]\ttraining's auc: 0.825369\tvalid_1's auc: 0.820567\n",
      "[11]\ttraining's auc: 0.82892\tvalid_1's auc: 0.82278\n",
      "[12]\ttraining's auc: 0.829948\tvalid_1's auc: 0.824091\n",
      "[13]\ttraining's auc: 0.832009\tvalid_1's auc: 0.82583\n",
      "[14]\ttraining's auc: 0.832787\tvalid_1's auc: 0.827129\n",
      "[15]\ttraining's auc: 0.832831\tvalid_1's auc: 0.827074\n",
      "[16]\ttraining's auc: 0.834462\tvalid_1's auc: 0.827697\n",
      "[17]\ttraining's auc: 0.838094\tvalid_1's auc: 0.830771\n",
      "[18]\ttraining's auc: 0.83958\tvalid_1's auc: 0.832673\n",
      "[19]\ttraining's auc: 0.840736\tvalid_1's auc: 0.834599\n",
      "[20]\ttraining's auc: 0.840759\tvalid_1's auc: 0.834564\n",
      "[21]\ttraining's auc: 0.840897\tvalid_1's auc: 0.834662\n",
      "[22]\ttraining's auc: 0.841231\tvalid_1's auc: 0.835626\n",
      "[23]\ttraining's auc: 0.841918\tvalid_1's auc: 0.836164\n",
      "[24]\ttraining's auc: 0.841962\tvalid_1's auc: 0.836187\n",
      "[25]\ttraining's auc: 0.842325\tvalid_1's auc: 0.836769\n",
      "[26]\ttraining's auc: 0.842821\tvalid_1's auc: 0.836765\n",
      "[27]\ttraining's auc: 0.843032\tvalid_1's auc: 0.836825\n",
      "[28]\ttraining's auc: 0.842994\tvalid_1's auc: 0.836604\n",
      "[29]\ttraining's auc: 0.843019\tvalid_1's auc: 0.836621\n",
      "[30]\ttraining's auc: 0.84301\tvalid_1's auc: 0.836512\n",
      "[31]\ttraining's auc: 0.843113\tvalid_1's auc: 0.836731\n",
      "[32]\ttraining's auc: 0.843087\tvalid_1's auc: 0.836889\n",
      "[33]\ttraining's auc: 0.843148\tvalid_1's auc: 0.836941\n",
      "[34]\ttraining's auc: 0.843682\tvalid_1's auc: 0.837658\n",
      "[35]\ttraining's auc: 0.844047\tvalid_1's auc: 0.838162\n",
      "[36]\ttraining's auc: 0.84458\tvalid_1's auc: 0.838393\n",
      "[37]\ttraining's auc: 0.844672\tvalid_1's auc: 0.838305\n",
      "[38]\ttraining's auc: 0.844721\tvalid_1's auc: 0.838353\n",
      "[39]\ttraining's auc: 0.844762\tvalid_1's auc: 0.838255\n",
      "[40]\ttraining's auc: 0.844732\tvalid_1's auc: 0.838249\n",
      "[41]\ttraining's auc: 0.844736\tvalid_1's auc: 0.83825\n",
      "[42]\ttraining's auc: 0.84476\tvalid_1's auc: 0.838227\n",
      "[43]\ttraining's auc: 0.844844\tvalid_1's auc: 0.838364\n",
      "[44]\ttraining's auc: 0.844852\tvalid_1's auc: 0.838364\n",
      "[45]\ttraining's auc: 0.844817\tvalid_1's auc: 0.838345\n",
      "[46]\ttraining's auc: 0.844777\tvalid_1's auc: 0.838312\n",
      "[47]\ttraining's auc: 0.844943\tvalid_1's auc: 0.838485\n",
      "[48]\ttraining's auc: 0.844961\tvalid_1's auc: 0.838502\n",
      "[49]\ttraining's auc: 0.844958\tvalid_1's auc: 0.838488\n",
      "[50]\ttraining's auc: 0.844939\tvalid_1's auc: 0.838565\n",
      "[51]\ttraining's auc: 0.844962\tvalid_1's auc: 0.838521\n",
      "[52]\ttraining's auc: 0.844995\tvalid_1's auc: 0.838611\n",
      "[53]\ttraining's auc: 0.845032\tvalid_1's auc: 0.83863\n",
      "[54]\ttraining's auc: 0.845044\tvalid_1's auc: 0.838616\n",
      "[55]\ttraining's auc: 0.845037\tvalid_1's auc: 0.838602\n",
      "[56]\ttraining's auc: 0.845028\tvalid_1's auc: 0.838602\n",
      "[57]\ttraining's auc: 0.845022\tvalid_1's auc: 0.838602\n",
      "[58]\ttraining's auc: 0.845057\tvalid_1's auc: 0.838603\n",
      "[59]\ttraining's auc: 0.84504\tvalid_1's auc: 0.83856\n",
      "[60]\ttraining's auc: 0.845018\tvalid_1's auc: 0.838564\n",
      "[61]\ttraining's auc: 0.845022\tvalid_1's auc: 0.838536\n",
      "[62]\ttraining's auc: 0.845085\tvalid_1's auc: 0.838513\n",
      "[63]\ttraining's auc: 0.84508\tvalid_1's auc: 0.838478\n",
      "[64]\ttraining's auc: 0.845053\tvalid_1's auc: 0.83855\n",
      "[65]\ttraining's auc: 0.845049\tvalid_1's auc: 0.838586\n",
      "[66]\ttraining's auc: 0.845104\tvalid_1's auc: 0.838588\n",
      "[67]\ttraining's auc: 0.845126\tvalid_1's auc: 0.838638\n",
      "[68]\ttraining's auc: 0.845121\tvalid_1's auc: 0.838643\n",
      "[69]\ttraining's auc: 0.845114\tvalid_1's auc: 0.838643\n",
      "[70]\ttraining's auc: 0.845114\tvalid_1's auc: 0.838643\n",
      "[71]\ttraining's auc: 0.845106\tvalid_1's auc: 0.838641\n",
      "[72]\ttraining's auc: 0.845097\tvalid_1's auc: 0.838635\n",
      "[73]\ttraining's auc: 0.845094\tvalid_1's auc: 0.838681\n",
      "[74]\ttraining's auc: 0.845089\tvalid_1's auc: 0.838686\n",
      "[75]\ttraining's auc: 0.845076\tvalid_1's auc: 0.838707\n",
      "[76]\ttraining's auc: 0.845081\tvalid_1's auc: 0.838737\n",
      "[77]\ttraining's auc: 0.845103\tvalid_1's auc: 0.838762\n",
      "[78]\ttraining's auc: 0.845113\tvalid_1's auc: 0.838729\n",
      "[79]\ttraining's auc: 0.845106\tvalid_1's auc: 0.838728\n",
      "[80]\ttraining's auc: 0.845134\tvalid_1's auc: 0.838725\n",
      "[81]\ttraining's auc: 0.845137\tvalid_1's auc: 0.83875\n",
      "[82]\ttraining's auc: 0.845136\tvalid_1's auc: 0.83875\n",
      "[83]\ttraining's auc: 0.845134\tvalid_1's auc: 0.838821\n",
      "[84]\ttraining's auc: 0.845142\tvalid_1's auc: 0.838831\n",
      "[85]\ttraining's auc: 0.845142\tvalid_1's auc: 0.838891\n",
      "[86]\ttraining's auc: 0.845141\tvalid_1's auc: 0.838891\n",
      "[87]\ttraining's auc: 0.845158\tvalid_1's auc: 0.838902\n",
      "[88]\ttraining's auc: 0.845176\tvalid_1's auc: 0.838903\n",
      "[89]\ttraining's auc: 0.845169\tvalid_1's auc: 0.838949\n",
      "[90]\ttraining's auc: 0.845181\tvalid_1's auc: 0.838984\n",
      "[91]\ttraining's auc: 0.8452\tvalid_1's auc: 0.83898\n",
      "[92]\ttraining's auc: 0.845208\tvalid_1's auc: 0.838993\n",
      "[93]\ttraining's auc: 0.845209\tvalid_1's auc: 0.839028\n",
      "[94]\ttraining's auc: 0.845207\tvalid_1's auc: 0.839025\n",
      "[95]\ttraining's auc: 0.845213\tvalid_1's auc: 0.839028\n",
      "[96]\ttraining's auc: 0.845229\tvalid_1's auc: 0.83899\n",
      "[97]\ttraining's auc: 0.845227\tvalid_1's auc: 0.838984\n",
      "[98]\ttraining's auc: 0.845259\tvalid_1's auc: 0.838941\n",
      "[99]\ttraining's auc: 0.84526\tvalid_1's auc: 0.838941\n",
      "[100]\ttraining's auc: 0.845329\tvalid_1's auc: 0.838854\n",
      "[101]\ttraining's auc: 0.845366\tvalid_1's auc: 0.838751\n",
      "[102]\ttraining's auc: 0.845405\tvalid_1's auc: 0.838769\n",
      "[103]\ttraining's auc: 0.845398\tvalid_1's auc: 0.838773\n",
      "[104]\ttraining's auc: 0.845396\tvalid_1's auc: 0.838763\n",
      "[105]\ttraining's auc: 0.845401\tvalid_1's auc: 0.838776\n",
      "[106]\ttraining's auc: 0.84539\tvalid_1's auc: 0.838803\n",
      "[107]\ttraining's auc: 0.845409\tvalid_1's auc: 0.838809\n",
      "[108]\ttraining's auc: 0.845411\tvalid_1's auc: 0.83883\n",
      "[109]\ttraining's auc: 0.845413\tvalid_1's auc: 0.838867\n",
      "[110]\ttraining's auc: 0.845431\tvalid_1's auc: 0.838825\n",
      "[111]\ttraining's auc: 0.845427\tvalid_1's auc: 0.838816\n",
      "[112]\ttraining's auc: 0.845427\tvalid_1's auc: 0.838837\n",
      "[113]\ttraining's auc: 0.845479\tvalid_1's auc: 0.838877\n",
      "Early stopping, best iteration is:\n",
      "[93]\ttraining's auc: 0.845209\tvalid_1's auc: 0.839028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.754786\tvalid_1's auc: 0.747752\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[2]\ttraining's auc: 0.782702\tvalid_1's auc: 0.778012\n",
      "[3]\ttraining's auc: 0.798866\tvalid_1's auc: 0.797507\n",
      "[4]\ttraining's auc: 0.799586\tvalid_1's auc: 0.797876\n",
      "[5]\ttraining's auc: 0.804732\tvalid_1's auc: 0.803122\n",
      "[6]\ttraining's auc: 0.811711\tvalid_1's auc: 0.812291\n",
      "[7]\ttraining's auc: 0.81553\tvalid_1's auc: 0.816608\n",
      "[8]\ttraining's auc: 0.820614\tvalid_1's auc: 0.822901\n",
      "[9]\ttraining's auc: 0.822497\tvalid_1's auc: 0.824785\n",
      "[10]\ttraining's auc: 0.822316\tvalid_1's auc: 0.824974\n",
      "[11]\ttraining's auc: 0.824297\tvalid_1's auc: 0.826624\n",
      "[12]\ttraining's auc: 0.825228\tvalid_1's auc: 0.828196\n",
      "[13]\ttraining's auc: 0.826868\tvalid_1's auc: 0.829477\n",
      "[14]\ttraining's auc: 0.828172\tvalid_1's auc: 0.829365\n",
      "[15]\ttraining's auc: 0.835134\tvalid_1's auc: 0.834464\n",
      "[16]\ttraining's auc: 0.835872\tvalid_1's auc: 0.834918\n",
      "[17]\ttraining's auc: 0.837313\tvalid_1's auc: 0.837275\n",
      "[18]\ttraining's auc: 0.838204\tvalid_1's auc: 0.838594\n",
      "[19]\ttraining's auc: 0.839021\tvalid_1's auc: 0.838798\n",
      "[20]\ttraining's auc: 0.839215\tvalid_1's auc: 0.838986\n",
      "[21]\ttraining's auc: 0.83942\tvalid_1's auc: 0.839733\n",
      "[22]\ttraining's auc: 0.839497\tvalid_1's auc: 0.839804\n",
      "[23]\ttraining's auc: 0.839518\tvalid_1's auc: 0.839756\n",
      "[24]\ttraining's auc: 0.840784\tvalid_1's auc: 0.841096\n",
      "[25]\ttraining's auc: 0.841238\tvalid_1's auc: 0.841644\n",
      "[26]\ttraining's auc: 0.84109\tvalid_1's auc: 0.841244\n",
      "[27]\ttraining's auc: 0.841395\tvalid_1's auc: 0.841129\n",
      "[28]\ttraining's auc: 0.842123\tvalid_1's auc: 0.841287\n",
      "[29]\ttraining's auc: 0.842182\tvalid_1's auc: 0.841485\n",
      "[30]\ttraining's auc: 0.842441\tvalid_1's auc: 0.841341\n",
      "[31]\ttraining's auc: 0.842488\tvalid_1's auc: 0.841219\n",
      "[32]\ttraining's auc: 0.842491\tvalid_1's auc: 0.841261\n",
      "[33]\ttraining's auc: 0.842568\tvalid_1's auc: 0.841427\n",
      "[34]\ttraining's auc: 0.842633\tvalid_1's auc: 0.841327\n",
      "[35]\ttraining's auc: 0.842627\tvalid_1's auc: 0.841312\n",
      "[36]\ttraining's auc: 0.843017\tvalid_1's auc: 0.841687\n",
      "[37]\ttraining's auc: 0.843108\tvalid_1's auc: 0.841883\n",
      "[38]\ttraining's auc: 0.843157\tvalid_1's auc: 0.841929\n",
      "[39]\ttraining's auc: 0.843285\tvalid_1's auc: 0.841848\n",
      "[40]\ttraining's auc: 0.843261\tvalid_1's auc: 0.841802\n",
      "[41]\ttraining's auc: 0.843244\tvalid_1's auc: 0.841843\n",
      "[42]\ttraining's auc: 0.843326\tvalid_1's auc: 0.841859\n",
      "[43]\ttraining's auc: 0.843264\tvalid_1's auc: 0.841786\n",
      "[44]\ttraining's auc: 0.843307\tvalid_1's auc: 0.841784\n",
      "[45]\ttraining's auc: 0.843332\tvalid_1's auc: 0.841797\n",
      "[46]\ttraining's auc: 0.843341\tvalid_1's auc: 0.84185\n",
      "[47]\ttraining's auc: 0.843372\tvalid_1's auc: 0.841821\n",
      "[48]\ttraining's auc: 0.84341\tvalid_1's auc: 0.841808\n",
      "[49]\ttraining's auc: 0.843378\tvalid_1's auc: 0.84177\n",
      "[50]\ttraining's auc: 0.843386\tvalid_1's auc: 0.841973\n",
      "[51]\ttraining's auc: 0.843392\tvalid_1's auc: 0.841964\n",
      "[52]\ttraining's auc: 0.84343\tvalid_1's auc: 0.842005\n",
      "[53]\ttraining's auc: 0.843475\tvalid_1's auc: 0.842055\n",
      "[54]\ttraining's auc: 0.843475\tvalid_1's auc: 0.842177\n",
      "[55]\ttraining's auc: 0.843493\tvalid_1's auc: 0.842158\n",
      "[56]\ttraining's auc: 0.843508\tvalid_1's auc: 0.842151\n",
      "[57]\ttraining's auc: 0.843525\tvalid_1's auc: 0.842242\n",
      "[58]\ttraining's auc: 0.843543\tvalid_1's auc: 0.842241\n",
      "[59]\ttraining's auc: 0.843563\tvalid_1's auc: 0.842216\n",
      "[60]\ttraining's auc: 0.843599\tvalid_1's auc: 0.84223\n",
      "[61]\ttraining's auc: 0.843607\tvalid_1's auc: 0.842222\n",
      "[62]\ttraining's auc: 0.843614\tvalid_1's auc: 0.842397\n",
      "[63]\ttraining's auc: 0.843637\tvalid_1's auc: 0.8424\n",
      "[64]\ttraining's auc: 0.843619\tvalid_1's auc: 0.842396\n",
      "[65]\ttraining's auc: 0.843599\tvalid_1's auc: 0.842386\n",
      "[66]\ttraining's auc: 0.843595\tvalid_1's auc: 0.842391\n",
      "[67]\ttraining's auc: 0.843651\tvalid_1's auc: 0.842393\n",
      "[68]\ttraining's auc: 0.843657\tvalid_1's auc: 0.842413\n",
      "[69]\ttraining's auc: 0.843658\tvalid_1's auc: 0.842375\n",
      "[70]\ttraining's auc: 0.84368\tvalid_1's auc: 0.842394\n",
      "[71]\ttraining's auc: 0.843668\tvalid_1's auc: 0.842395\n",
      "[72]\ttraining's auc: 0.843678\tvalid_1's auc: 0.842479\n",
      "[73]\ttraining's auc: 0.843673\tvalid_1's auc: 0.842472\n",
      "[74]\ttraining's auc: 0.843677\tvalid_1's auc: 0.842463\n",
      "[75]\ttraining's auc: 0.843696\tvalid_1's auc: 0.842451\n",
      "[76]\ttraining's auc: 0.843669\tvalid_1's auc: 0.842444\n",
      "[77]\ttraining's auc: 0.843696\tvalid_1's auc: 0.842489\n",
      "[78]\ttraining's auc: 0.843701\tvalid_1's auc: 0.842505\n",
      "[79]\ttraining's auc: 0.843692\tvalid_1's auc: 0.842496\n",
      "[80]\ttraining's auc: 0.843683\tvalid_1's auc: 0.84249\n",
      "[81]\ttraining's auc: 0.843688\tvalid_1's auc: 0.8425\n",
      "[82]\ttraining's auc: 0.843675\tvalid_1's auc: 0.842478\n",
      "[83]\ttraining's auc: 0.843678\tvalid_1's auc: 0.842464\n",
      "[84]\ttraining's auc: 0.843671\tvalid_1's auc: 0.842458\n",
      "[85]\ttraining's auc: 0.843667\tvalid_1's auc: 0.842438\n",
      "[86]\ttraining's auc: 0.843662\tvalid_1's auc: 0.842441\n",
      "[87]\ttraining's auc: 0.843659\tvalid_1's auc: 0.842429\n",
      "[88]\ttraining's auc: 0.843654\tvalid_1's auc: 0.842425\n",
      "[89]\ttraining's auc: 0.843668\tvalid_1's auc: 0.842453\n",
      "[90]\ttraining's auc: 0.843671\tvalid_1's auc: 0.842455\n",
      "[91]\ttraining's auc: 0.843677\tvalid_1's auc: 0.842452\n",
      "[92]\ttraining's auc: 0.843689\tvalid_1's auc: 0.842481\n",
      "[93]\ttraining's auc: 0.843691\tvalid_1's auc: 0.842485\n",
      "[94]\ttraining's auc: 0.843689\tvalid_1's auc: 0.842479\n",
      "[95]\ttraining's auc: 0.843689\tvalid_1's auc: 0.84248\n",
      "[96]\ttraining's auc: 0.843696\tvalid_1's auc: 0.842465\n",
      "[97]\ttraining's auc: 0.84371\tvalid_1's auc: 0.842591\n",
      "[98]\ttraining's auc: 0.843707\tvalid_1's auc: 0.842578\n",
      "[99]\ttraining's auc: 0.843694\tvalid_1's auc: 0.842587\n",
      "[100]\ttraining's auc: 0.843753\tvalid_1's auc: 0.842566\n",
      "[101]\ttraining's auc: 0.843773\tvalid_1's auc: 0.842557\n",
      "[102]\ttraining's auc: 0.843778\tvalid_1's auc: 0.842558\n",
      "[103]\ttraining's auc: 0.843798\tvalid_1's auc: 0.84255\n",
      "[104]\ttraining's auc: 0.843866\tvalid_1's auc: 0.842564\n",
      "[105]\ttraining's auc: 0.843906\tvalid_1's auc: 0.842559\n",
      "[106]\ttraining's auc: 0.843917\tvalid_1's auc: 0.842572\n",
      "[107]\ttraining's auc: 0.843912\tvalid_1's auc: 0.842583\n",
      "[108]\ttraining's auc: 0.843907\tvalid_1's auc: 0.842573\n",
      "[109]\ttraining's auc: 0.843901\tvalid_1's auc: 0.842554\n",
      "[110]\ttraining's auc: 0.843894\tvalid_1's auc: 0.842552\n",
      "[111]\ttraining's auc: 0.843899\tvalid_1's auc: 0.842549\n",
      "[112]\ttraining's auc: 0.843911\tvalid_1's auc: 0.842543\n",
      "[113]\ttraining's auc: 0.843902\tvalid_1's auc: 0.842552\n",
      "[114]\ttraining's auc: 0.843902\tvalid_1's auc: 0.842554\n",
      "[115]\ttraining's auc: 0.843929\tvalid_1's auc: 0.842571\n",
      "[116]\ttraining's auc: 0.843937\tvalid_1's auc: 0.842563\n",
      "[117]\ttraining's auc: 0.843942\tvalid_1's auc: 0.842529\n",
      "Early stopping, best iteration is:\n",
      "[97]\ttraining's auc: 0.84371\tvalid_1's auc: 0.842591\n",
      "                  TrainingSet  ValidationSet\n",
      "bagging_fraction                            \n",
      "0.91                 0.844525       0.840947\n"
     ]
    }
   ],
   "source": [
    "cv('bagging_fraction', [0.91])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LibFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "path = \"/mnt/d/Data/mangaki-data-challenge/libfm/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_iter':340000, \n",
    "    'init_stdev':0.01,\n",
    "    'l2_reg_w':0.00025,\n",
    "    'l2_reg_V':0.5,\n",
    "    'rank':1,\n",
    "    'step_size':0.02\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "from fastFM import sgd\n",
    "\n",
    "def train_fm(train, valid, trainy, validy):\n",
    "    fm = sgd.FMClassification(**params)\n",
    "    fm.fit(train, np.require(trainy*2-1, dtype=np.int))\n",
    "    return (roc_auc_score(trainy, fm.predict_proba(train)), roc_auc_score(validy, fm.predict_proba(valid)))\n",
    "\n",
    "def cv_fm(param, paramlst):\n",
    "    trainauc = [0.0]*len(paramlst)\n",
    "    validauc = [0.0]*len(paramlst)\n",
    "    for i, p in enumerate(paramlst):\n",
    "        params[param]=p\n",
    "        tv = [0,0,0]\n",
    "        vv = [0,0,0]\n",
    "        for fold in [1,2,3]:\n",
    "            train, ty = load_svmlight_file(path+\"train_{0}.csv\".format(fold))\n",
    "            valid, vy = load_svmlight_file(path+\"valid_{0}.csv\".format(fold))\n",
    "            ta = pd.read_csv(data+'train_{0}.csv'.format(str(fold))).fillna(0)\n",
    "            va = pd.read_csv(data+'valid_{0}.csv'.format(str(fold))).fillna(0)\n",
    "            tv[fold-1], vv[fold-1] = train_fm(train, valid, ty, vy)\n",
    "        trainauc[i]=np.mean(tv)\n",
    "        validauc[i]=np.mean(vv)\n",
    "    paramtable = pd.DataFrame({\n",
    "        'TrainingSet': trainauc,\n",
    "        'ValidationSet': validauc\n",
    "    }, columns=['TrainingSet', 'ValidationSet'], index=pd.Index(paramlst, name=param))\n",
    "    print(paramtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          TrainingSet  ValidationSet\n",
      "l2_reg_V                            \n",
      "0.4          0.920071       0.806509\n",
      "0.5          0.920067       0.806510\n",
      "0.6          0.920065       0.806509\n"
     ]
    }
   ],
   "source": [
    "cv_fm('l2_reg_V', [0.4, 0.5, 0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
